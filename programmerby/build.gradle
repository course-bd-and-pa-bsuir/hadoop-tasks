apply plugin: 'java'
apply plugin: 'scala'
apply plugin: 'idea'
apply plugin: 'eclipse'

sourceCompatibility = 1.6
targetCompatibility = 1.6
version = '1.0'

repositories {
    mavenCentral()
    maven {
        url 'https://repository.cloudera.com/artifactory/cloudera-repos/'
    }
}

configurations {
    provided
}

sourceSets {
    main {
        compileClasspath += configurations.provided
    }
}

idea {
    module {
        // (заменил PROVIDED -> COMPILE) Чтобы можно было запустить прямо из IDEA
        scopes.COMPILE.plus += [ configurations.provided ]
    }
}

eclipse {
    classpath {
        defaultOutputDir = file("${buildDir}/eclipse-classes")
        plusConfigurations += [ configurations.provided ]
        noExportConfigurations += [ configurations.provided ]
        downloadSources = true
    }
}

dependencies {
    // Spark тянет за собой свою версию Hadoop
    //provided 'org.apache.hadoop:hadoop-client:2.5.0-cdh5.3.3'

    provided 'org.apache.spark:spark-core_2.10:1.3.0'
    provided 'org.apache.spark:spark-mllib_2.10:1.3.0'
    provided 'org.apache.spark:spark-streaming_2.10:1.3.0'
    provided 'org.apache.spark:spark-streaming-twitter_2.10:1.3.0'
    provided 'org.scala-lang:scala-library:2.10.4'

    compile 'com.codesnippets4all:quick-json:1.0.4'

    testCompile group: 'junit', name: 'junit', version: '4.11'
}

// Emulate Maven shade plugin with a fat jar.
// http://docs.codehaus.org/display/GRADLE/Cookbook#Cookbook-Creatingafatjar
jar {
    from configurations.compile.collect { it.isDirectory() ? it : zipTree(it) }
}

// Example:
// gradle runSpark -PsparkMain="programmerby.SparkPi" -PsparkArgs="local 100"
task runSpark(dependsOn: 'jar', type: JavaExec) {
    classpath = files(jar.archivePath, configurations.provided)
    maxHeapSize = '1024m'

    // Set main class
    if (project.hasProperty('sparkMain')) {
        main = sparkMain
    }
    // Set args
    if (project.hasProperty('sparkArgs')) {
        args(sparkArgs.split(' '))
    }
}